{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd5cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "import torch\n",
    "import kan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0639de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hi"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = sympy.Function('hi')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e51ac405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\operatorname{hi}{\\left(x \\right)}$"
      ],
      "text/plain": [
       "hi(x)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3180e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda x : torch.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3237b559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<code object <lambda> at 0x0000026C0C90FC30, file \"C:\\Users\\taoha\\AppData\\Local\\Temp\\ipykernel_36368\\259579469.py\", line 1>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.__code__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86685e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<lambda>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41e08df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{g=}'.split('=')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b94f33bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g = lambda x : torch.tanh(x)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "lines = inspect.getsource(g)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb137fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(lambda x : torch.tanh(x))'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fstr = f'{(lambda x : torch.tanh(x))=}'.split('=')[0]\n",
    "fstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60486205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\operatorname{(lambda x : torch.tanh(x))}{\\left(x \\right)} + 1$"
      ],
      "text/plain": [
       "(lambda x : torch.tanh(x))(x) + 1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sympy.Function(fstr)('x') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "951f78d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x[:, 0]\n",
    "import kan.utils as ku\n",
    "dataset = ku.create_dataset(f, train_num = 10, test_num = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35817253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "saving model version 0.1\n"
     ]
    }
   ],
   "source": [
    "kan_model = kan.KAN(width=[1, 1])\n",
    "kan_model(dataset['train_input'])\n",
    "tanh = lambda x : torch.tanh(x)\n",
    "kan_model.fix_symbolic(0, 0, 0, tanh)\n",
    "# kan_model.fix_symbolic(0, 0, 0, lambda x : torch.tanh(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86c4ba17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x200 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kan_model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "495dbad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import inspect\n",
    "def symbolic_formula(self, var=None, normalizer=None, output_normalizer = None):\n",
    "    '''\n",
    "    get symbolic formula\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        var : None or a list of sympy expression\n",
    "            input variables\n",
    "        normalizer : [mean, std]\n",
    "        output_normalizer : [mean, std]\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "        None\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> from kan import *\n",
    "    >>> model = KAN(width=[2,1,1], grid=5, k=3, noise_scale=0.0, seed=0)\n",
    "    >>> f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]])+x[:,[1]]**2)\n",
    "    >>> dataset = create_dataset(f, n_var=3)\n",
    "    >>> model.fit(dataset, opt='LBFGS', steps=20, lamb=0.001);\n",
    "    >>> model.auto_symbolic()\n",
    "    >>> model.symbolic_formula()[0][0]\n",
    "    '''\n",
    "    \n",
    "    symbolic_acts = []\n",
    "    symbolic_acts_premult = []\n",
    "    x = []\n",
    "\n",
    "    def ex_round(ex1, n_digit):\n",
    "        ex2 = ex1\n",
    "        for a in sympy.preorder_traversal(ex1):\n",
    "            if isinstance(a, sympy.Float):\n",
    "                ex2 = ex2.subs(a, round(a, n_digit))\n",
    "        return ex2\n",
    "\n",
    "    # define variables\n",
    "    if var == None:\n",
    "        for ii in range(1, self.width[0][0] + 1):\n",
    "            exec(f\"x{ii} = sympy.Symbol('x_{ii}')\")\n",
    "            exec(f\"x.append(x{ii})\")\n",
    "    elif isinstance(var[0], sympy.Expr):\n",
    "        x = var\n",
    "    else:\n",
    "        x = [sympy.symbols(var_) for var_ in var]\n",
    "\n",
    "    x0 = x\n",
    "\n",
    "    if normalizer != None:\n",
    "        mean = normalizer[0]\n",
    "        std = normalizer[1]\n",
    "        x = [(x[i] - mean[i]) / std[i] for i in range(len(x))]\n",
    "\n",
    "    symbolic_acts.append(x)\n",
    "\n",
    "    for l in range(len(self.width_in) - 1):\n",
    "        num_sum = self.width[l + 1][0]\n",
    "        num_mult = self.width[l + 1][1]\n",
    "        y = []\n",
    "        for j in range(self.width_out[l + 1]):\n",
    "            yj = 0.\n",
    "            for i in range(self.width_in[l]):\n",
    "                a, b, c, d = self.symbolic_fun[l].affine[j, i]\n",
    "                sympy_fun = self.symbolic_fun[l].funs_sympy[j][i]\n",
    "                try:\n",
    "                    yj += c * sympy_fun(a * x[i] + b) + d\n",
    "                except:\n",
    "                    print(sympy_fun)\n",
    "                    print(inspect.getsource(sympy_fun))\n",
    "                    print(dill.source.getsource(sympy_fun))\n",
    "                    print(f'{sympy_fun=}')\n",
    "                    print(f'{self.symbolic_fun[l].funs_sympy[j][i]=}')\n",
    "                    print(f'{sympy_fun=}'.split('=')[0])\n",
    "                    # sympy_fun = sympy.Function(f'{sympy_fun=}'.split('=')[0])\n",
    "                    sympy_fun = sympy.Function(f'({inspect.getsource(sympy_fun)})')\n",
    "                    yj += c * sympy_fun(a * x[i] + b) + d\n",
    "                    # yj += c * sympy.tanh(a * x[i] + b) + d\n",
    "                    print('make sure all activations need to be converted to symbolic formulas first!')\n",
    "                    # return\n",
    "            yj = self.subnode_scale[l][j] * yj + self.subnode_bias[l][j]\n",
    "            y.append(yj)\n",
    "                \n",
    "        symbolic_acts_premult.append(y)\n",
    "            \n",
    "        mult = []\n",
    "        for k in range(num_mult):\n",
    "            if isinstance(self.mult_arity, int):\n",
    "                mult_arity = self.mult_arity\n",
    "            else:\n",
    "                mult_arity = self.mult_arity[l+1][k]\n",
    "            for i in range(mult_arity-1):\n",
    "                if i == 0:\n",
    "                    mult_k = y[num_sum+2*k] * y[num_sum+2*k+1]\n",
    "                else:\n",
    "                    mult_k = mult_k * y[num_sum+2*k+i+1]\n",
    "            mult.append(mult_k)\n",
    "            \n",
    "        y = y[:num_sum] + mult\n",
    "        \n",
    "        for j in range(self.width_in[l+1]):\n",
    "            y[j] = self.node_scale[l][j] * y[j] + self.node_bias[l][j]\n",
    "        \n",
    "        x = y\n",
    "        symbolic_acts.append(x)\n",
    "\n",
    "    if output_normalizer != None:\n",
    "        output_layer = symbolic_acts[-1]\n",
    "        means = output_normalizer[0]\n",
    "        stds = output_normalizer[1]\n",
    "\n",
    "        assert len(output_layer) == len(means), 'output_normalizer does not match the output layer'\n",
    "        assert len(output_layer) == len(stds), 'output_normalizer does not match the output layer'\n",
    "        \n",
    "        output_layer = [(output_layer[i] * stds[i] + means[i]) for i in range(len(output_layer))]\n",
    "        symbolic_acts[-1] = output_layer\n",
    "\n",
    "\n",
    "    self.symbolic_acts = [[symbolic_acts[l][i] for i in range(len(symbolic_acts[l]))] for l in range(len(symbolic_acts))]\n",
    "    self.symbolic_acts_premult = [[symbolic_acts_premult[l][i] for i in range(len(symbolic_acts_premult[l]))] for l in range(len(symbolic_acts_premult))]\n",
    "\n",
    "    out_dim = len(symbolic_acts[-1])\n",
    "    #return [symbolic_acts[-1][i] for i in range(len(symbolic_acts[-1]))], x0\n",
    "    return [symbolic_acts[-1][i] for i in range(len(symbolic_acts[-1]))], x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d774cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <lambda> at 0x000001CD226DFCE0>\n",
      "tanh = lambda x : torch.tanh(x)\n",
      "\n",
      "tanh = lambda x : torch.tanh(x)\n",
      "\n",
      "sympy_fun=<function <lambda> at 0x000001CD226DFCE0>\n",
      "self.symbolic_fun[l].funs_sympy[j][i]=<function <lambda> at 0x000001CD226DFCE0>\n",
      "sympy_fun\n",
      "make sure all activations need to be converted to symbolic formulas first!\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.0 \\operatorname{(tanh = lambda x : torch.tanh(x)\n",
       ")}{\\left(1.0 x_{1} \\right)}$"
      ],
      "text/plain": [
       "1.0*(tanh = lambda x : torch.tanh(x)\n",
       ")(1.0*x_1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbolic_formula(kan_model)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170c7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
