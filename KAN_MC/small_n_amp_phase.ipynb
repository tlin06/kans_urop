{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries import lib\n",
    "from libraries.NeuralStates import *\n",
    "import qutip as qt\n",
    "import torch.nn as nn \n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from kan import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp_phase(nn_output):\n",
    "    return nn_output[:, 0] * torch.exp(1.j * 2 * np.pi * nn_output[:, 1])\n",
    "def bitflip_x(x, N, flips):\n",
    "    new_x = x\n",
    "    for _ in range(flips):\n",
    "        new_x = x ^ (1 << npr.randint(0, N))\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, J, Gamma = 6, 1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.727406610312546\n"
     ]
    }
   ],
   "source": [
    "true_gse = lib.ground_state_energy(Gamma, N)\n",
    "print(true_gse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "input = lib.generate_input_torch(N)\n",
    "def amp_phase(nn_output):\n",
    "    return nn_output[:, 0] * torch.exp(1.j * 2 * np.pi * nn_output[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "kan_model = KAN(width=[N, N, 2], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = nn.Sequential(\n",
    "    nn.Linear(N, 5 * N),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(5 * N, 2),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "data_rate = 1\n",
    "num_samples = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amp_phase(kan_model(input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amp_phase(mlp_model(input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:813: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:823: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:824: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:825: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(-4.6566, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-4.9741, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.1721, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.3390, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.7390, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.0426, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.6930, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.4972, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.4480, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.2418, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.6882, grad_fn=<SelectBackward0>)\n",
      "epoch 1\n",
      "loss tensor(-5.3451, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-1.0916, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.6871, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.7673, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.9888, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.2421, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.3193, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-4.1191, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.3012, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.7932, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.0891, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.8681, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.9668, grad_fn=<SelectBackward0>)\n",
      "epoch 2\n",
      "loss tensor(-5.7637, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.9873, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.4431, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.5410, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.6316, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.7068, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.5782, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-7.1567, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.0590, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.4070, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-7.4140, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-7.5617, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-8.7579, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-8.2801, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-8.3434, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-7.4487, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.9029, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.9845, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.5509, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-7.9178, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.2734, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.0673, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.4487, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.5080, grad_fn=<SelectBackward0>)\n",
      "epoch 3\n",
      "loss tensor(-5.5343, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-5.4355, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.0752, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.9071, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.4421, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-6.1599, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-7.1846, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-8.6631, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-4.8311, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-8.1751, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-7.3961, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-8.4474, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-8.7039, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-0.5561, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-8.7518, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-10.0170, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-7.6040, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-8.2931, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-7.8409, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-9.8558, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-9.3112, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-8.4390, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-0.3789, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-0.9944, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-4.6515, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.3420, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.6132, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-7.9252, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-8.5547, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-7.0564, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-9.0680, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-9.7337, grad_fn=<SelectBackward0>)\n",
      "epoch 4\n",
      "loss tensor(-8.4715, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-0.4161, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-1.3698, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-4.6242, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.6076, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-4.1022, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-9.1345, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-9.3013, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-8.5572, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-9.3837, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-11.3291, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-7.7794, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-8.8777, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-9.4056, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.4370, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-9.1307, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-8.7907, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-9.8754, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-7.9195, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-10.8194, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "vars = (N, J, Gamma)\n",
    "loss_fn = lib.TFIM_expectation_using_locals\n",
    "epochs = []\n",
    "loss_data = []\n",
    "optimizer = LBFGS(kan_model.parameters(), lr=1, history_size=10, line_search_fn=\"strong_wolfe\", tolerance_grad=1e-32, tolerance_change=1e-32, tolerance_ys=1e-32)\n",
    "for epoch in range(num_epochs):\n",
    "    print('epoch', epoch)\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(MHNeuralState(N, kan_model, amp_phase, lambda x : bitflip_x(x, N, 1), 2 ** (N - 1), num_samples), N, J, Gamma, model, amp_phase)\n",
    "        loss.backward()\n",
    "        print('loss', loss)\n",
    "        loss_data.append(loss)\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    epochs.append(epoch)\n",
    "    # loss_data.append(loss_fn(model(input), vars, amp_phase).item())\n",
    "\n",
    "# find groud state\n",
    "gs = lib.model_to_ground_state(kan_model, input, amp_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:813: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:823: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:824: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:825: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-7.8717, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(MHNeuralState(N, kan_model, amp_phase, lambda x : bitflip_x(x, N, 1), 2 ** (N - 1), num_samples), N, J, Gamma, model, amp_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-4.6566, grad_fn=<SelectBackward0>),\n",
       " tensor(-4.9741, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.1721, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.3390, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.7390, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.0426, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.6930, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.4972, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.4480, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.2418, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.6882, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.3451, grad_fn=<SelectBackward0>),\n",
       " tensor(-1.0916, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.6871, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.7673, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.9888, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.2421, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.3193, grad_fn=<SelectBackward0>),\n",
       " tensor(-4.1191, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.3012, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.7932, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.0891, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.8681, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.9668, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.7637, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.9873, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.4431, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.5410, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.6316, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.7068, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.5782, grad_fn=<SelectBackward0>),\n",
       " tensor(-7.1567, grad_fn=<SelectBackward0>),\n",
       " tensor(-3.0590, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.4070, grad_fn=<SelectBackward0>),\n",
       " tensor(-7.4140, grad_fn=<SelectBackward0>),\n",
       " tensor(-7.5617, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.7579, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.2801, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.3434, grad_fn=<SelectBackward0>),\n",
       " tensor(-7.4487, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.9029, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.9845, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.5509, grad_fn=<SelectBackward0>),\n",
       " tensor(-7.9178, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.2734, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.0673, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.4487, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.5080, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.5343, grad_fn=<SelectBackward0>),\n",
       " tensor(-5.4355, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.0752, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.9071, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.4421, grad_fn=<SelectBackward0>),\n",
       " tensor(-6.1599, grad_fn=<SelectBackward0>),\n",
       " tensor(-7.1846, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.6631, grad_fn=<SelectBackward0>),\n",
       " tensor(-4.8311, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.1751, grad_fn=<SelectBackward0>),\n",
       " tensor(-7.3961, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.4474, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.7039, grad_fn=<SelectBackward0>),\n",
       " tensor(-0.5561, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.7518, grad_fn=<SelectBackward0>),\n",
       " tensor(-10.0170, grad_fn=<SelectBackward0>),\n",
       " tensor(-7.6040, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.2931, grad_fn=<SelectBackward0>),\n",
       " tensor(-7.8409, grad_fn=<SelectBackward0>),\n",
       " tensor(-9.8558, grad_fn=<SelectBackward0>),\n",
       " tensor(-9.3112, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.4390, grad_fn=<SelectBackward0>),\n",
       " tensor(-0.3789, grad_fn=<SelectBackward0>),\n",
       " tensor(-0.9944, grad_fn=<SelectBackward0>),\n",
       " tensor(-4.6515, grad_fn=<SelectBackward0>),\n",
       " tensor(-3.3420, grad_fn=<SelectBackward0>),\n",
       " tensor(-3.6132, grad_fn=<SelectBackward0>),\n",
       " tensor(-7.9252, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.5547, grad_fn=<SelectBackward0>),\n",
       " tensor(-7.0564, grad_fn=<SelectBackward0>),\n",
       " tensor(-9.0680, grad_fn=<SelectBackward0>),\n",
       " tensor(-9.7337, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.4715, grad_fn=<SelectBackward0>),\n",
       " tensor(-0.4161, grad_fn=<SelectBackward0>),\n",
       " tensor(-1.3698, grad_fn=<SelectBackward0>),\n",
       " tensor(-4.6242, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.6076, grad_fn=<SelectBackward0>),\n",
       " tensor(-4.1022, grad_fn=<SelectBackward0>),\n",
       " tensor(-9.1345, grad_fn=<SelectBackward0>),\n",
       " tensor(-9.3013, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.5572, grad_fn=<SelectBackward0>),\n",
       " tensor(-9.3837, grad_fn=<SelectBackward0>),\n",
       " tensor(-11.3291, grad_fn=<SelectBackward0>),\n",
       " tensor(-7.7794, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.8777, grad_fn=<SelectBackward0>),\n",
       " tensor(-9.4056, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.4370, grad_fn=<SelectBackward0>),\n",
       " tensor(-9.1307, grad_fn=<SelectBackward0>),\n",
       " tensor(-8.7907, grad_fn=<SelectBackward0>),\n",
       " tensor(-9.8754, grad_fn=<SelectBackward0>),\n",
       " tensor(-7.9195, grad_fn=<SelectBackward0>),\n",
       " tensor(-10.8194, grad_fn=<SelectBackward0>)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.0150096436544\n"
     ]
    }
   ],
   "source": [
    "true_gse = lib.ground_state_energy(Gamma, N)\n",
    "print(true_gse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "kan_model_2 = KAN(width=[N, N, 2], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:813: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:823: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:824: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:825: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(-0.2644, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-0.5371, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-0.6150, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-0.7231, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-1.2846, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-1.6233, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.1897, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.2173, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.2149, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.4127, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.4947, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.3667, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.5072, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.6519, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.0092, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.7574, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-1.8003, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-1.6991, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.9368, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.1083, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.9081, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-1.8715, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.8734, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-1.7581, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.0293, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.8824, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.8890, grad_fn=<SelectBackward0>)\n",
      "epoch 1\n",
      "loss tensor(-2.9813, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.1181, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.2855, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-0.3117, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.6335, grad_fn=<SelectBackward0>)\n",
      "loss tensor(0.0698, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-0.1018, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.6005, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.7191, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.5797, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.5394, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.5673, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.5112, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.5492, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.4883, grad_fn=<SelectBackward0>)\n",
      "epoch 2\n",
      "loss tensor(-3.6023, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.5103, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.6802, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.4439, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.6500, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.7023, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.4424, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.4689, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.5044, grad_fn=<SelectBackward0>)\n",
      "epoch 3\n",
      "loss tensor(-2.3040, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.0837, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.8974, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.3423, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.1024, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-0.8275, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.5694, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.1268, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.9896, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.9751, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.9793, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.1066, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.9047, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.1317, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.3074, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.4520, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.5621, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.0245, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.0265, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.2421, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.4749, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.4451, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.3938, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.4192, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-2.3260, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.4731, grad_fn=<SelectBackward0>)\n",
      "epoch 4\n",
      "loss tensor(-3.5201, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.1850, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-4.1862, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.1884, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.4133, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.4389, grad_fn=<SelectBackward0>)\n",
      "loss tensor(-3.6113, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "vars = (N, J, Gamma)\n",
    "loss_fn = lib.TFIM_expectation_using_locals\n",
    "epochs = []\n",
    "loss_data = []\n",
    "optimizer = LBFGS(kan_model_2.parameters(), lr=1, history_size=10, line_search_fn=\"strong_wolfe\", tolerance_grad=1e-32, tolerance_change=1e-32, tolerance_ys=1e-32)\n",
    "for epoch in range(num_epochs):\n",
    "    print('epoch', epoch)\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(MHNeuralState(N, kan_model_2, amp_phase, lambda x : bitflip_x(x, N, 1), 2 ** (N - 1), num_samples), N, J, Gamma, kan_model_2, amp_phase)\n",
    "        loss.backward()\n",
    "        print('loss', loss)\n",
    "        loss_data.append(loss)\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    epochs.append(epoch)\n",
    "    # loss_data.append(loss_fn(model(input), vars, amp_phase).item())\n",
    "\n",
    "# find groud state\n",
    "gs = lib.model_to_ground_state(kan_model_2, input, amp_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:813: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:823: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:824: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:825: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-3.9516, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(MHNeuralState(N, kan_model_2, amp_phase, lambda x : bitflip_x(x, N, 1), 2 ** (N - 1), num_samples), N, J, Gamma, kan_model_2, amp_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Quantum object: dims=[[64], [1]], shape=(64, 1), type='ket', dtype=Dense$$\\left(\\begin{array}{cc}(-0.232-0.020j)\\\\(-0.123-0.047j)\\\\(-0.104+0.024j)\\\\(-0.089-0.010j)\\\\(-0.088+0.016j)\\\\\\vdots\\\\(0.182-0.088j)\\\\(0.134-0.122j)\\\\(0.209-0.185j)\\\\(0.146-0.118j)\\\\(0.345-0.376j)\\end{array}\\right)$$"
      ],
      "text/plain": [
       "Quantum object: dims=[[64], [1]], shape=(64, 1), type='ket', dtype=Dense\n",
       "Qobj data =\n",
       "[[-0.23204908-0.02012957j]\n",
       " [-0.12277526-0.04724472j]\n",
       " [-0.10423242+0.02404439j]\n",
       " [-0.08871173-0.00979267j]\n",
       " [-0.08819614+0.01646521j]\n",
       " [-0.01706136-0.00103092j]\n",
       " [ 0.02484111-0.01074945j]\n",
       " [-0.01812894+0.00238609j]\n",
       " [-0.12355423+0.02413674j]\n",
       " [-0.05533284-0.00480766j]\n",
       " [-0.02141453+0.01131867j]\n",
       " [-0.03531292+0.00753819j]\n",
       " [ 0.01419587-0.00649789j]\n",
       " [ 0.01476056-0.00332174j]\n",
       " [ 0.05082028-0.03607117j]\n",
       " [ 0.04365736-0.02122965j]\n",
       " [-0.15410417-0.01075705j]\n",
       " [-0.02665552-0.00839565j]\n",
       " [-0.02242329+0.00359524j]\n",
       " [-0.00810817-0.00129486j]\n",
       " [-0.00732632+0.00168221j]\n",
       " [ 0.05612388-0.0037317j ]\n",
       " [ 0.07839926-0.03149233j]\n",
       " [ 0.05943369-0.01034554j]\n",
       " [-0.03042705+0.00539996j]\n",
       " [ 0.04762545+0.00177914j]\n",
       " [ 0.06086858-0.02148112j]\n",
       " [ 0.04933832-0.00557357j]\n",
       " [ 0.07703555-0.04014205j]\n",
       " [ 0.10479107-0.04004547j]\n",
       " [ 0.10738856-0.06629593j]\n",
       " [ 0.19050989-0.09818576j]\n",
       " [-0.10310572+0.02362342j]\n",
       " [-0.05462633-0.00379136j]\n",
       " [-0.02750775+0.01215114j]\n",
       " [ 0.01226155-0.0025646j ]\n",
       " [ 0.03853667-0.01917732j]\n",
       " [ 0.03007626-0.00762839j]\n",
       " [ 0.05383411-0.03221199j]\n",
       " [ 0.0827596 -0.03909845j]\n",
       " [-0.01098454+0.00679702j]\n",
       " [ 0.01415157-0.00495935j]\n",
       " [ 0.00606629-0.0053907j ]\n",
       " [ 0.04646522-0.03375038j]\n",
       " [ 0.06821018-0.0637564j ]\n",
       " [ 0.07809708-0.06027964j]\n",
       " [ 0.04056782-0.04443935j]\n",
       " [ 0.15431464-0.18595921j]\n",
       " [-0.00240953+0.00043577j]\n",
       " [ 0.06236737+0.00334253j]\n",
       " [ 0.07117605-0.01676439j]\n",
       " [ 0.11166291-0.00806907j]\n",
       " [ 0.11052251-0.05866944j]\n",
       " [ 0.12530367-0.04695911j]\n",
       " [ 0.12326434-0.05768541j]\n",
       " [ 0.23757459-0.10826751j]\n",
       " [ 0.09224805-0.04353078j]\n",
       " [ 0.12542868-0.03829694j]\n",
       " [ 0.08820164-0.04458033j]\n",
       " [ 0.18185356-0.08831257j]\n",
       " [ 0.13384458-0.12216651j]\n",
       " [ 0.20916159-0.18544108j]\n",
       " [ 0.14576438-0.11799807j]\n",
       " [ 0.34453759-0.37587792j]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
