{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c998c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import qutip as qt\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import libraries.utils as utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dccc1468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_samples(state_nums, N):\n",
    "    # state_nums = torch.tensor(state_nums, dtype=torch.long)  # shape: (B,)\n",
    "    powers = torch.arange(N, dtype=torch.long)               # shape: (N,)\n",
    "    bits = (state_nums.unsqueeze(1) >> powers) & 1           # shape: (B, N)\n",
    "    return bits.to(torch.float32)\n",
    "def bitflip_batch(xs, N, flips):\n",
    "    \"\"\"\n",
    "    Vectorized random bit flips on a batch of integers.\n",
    "\n",
    "    Args:\n",
    "        xs (Tensor): shape (B,), integers\n",
    "        N (int): number of bits\n",
    "        flips (int): number of random bit flips per element\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape (B,), integers after bit flips\n",
    "    \"\"\"\n",
    "    B = xs.shape[0]\n",
    "    xs = xs.clone()\n",
    "\n",
    "    # Generate random bit indices for each flip and sample\n",
    "    bit_indices = torch.randint(0, N, size=(B, flips))\n",
    "\n",
    "    # Compute bitmasks: 1 << bit index\n",
    "    bitmasks = (1 << bit_indices)  # shape: (B, flips)\n",
    "\n",
    "    flip_masks = bitmasks[:, 0]\n",
    "    for i in range(1, flips):\n",
    "        flip_masks = flip_masks ^ bitmasks[:, i]\n",
    "\n",
    "    return xs ^ flip_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8d1341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries.NeuralStates import SparseStateVector\n",
    "class MHNeuralState(SparseStateVector):\n",
    "    def __init__(self, N, model, output_to_psi, x_func, x0, num_samples, burnin = 0, lag = 0, chains = 1, new = False):\n",
    "        \"\"\"\n",
    "        Initializes distribution of samples and vector values\n",
    "\n",
    "        Args:\n",
    "            N (int): number of qubits\n",
    "            model: torch model representing psi(x), which returns complex amplitude given integer state\n",
    "            output_to_psi (function): takes in output of model to compute complex amplitude\n",
    "            x_func (function): takes in state x and generates proposal x*\n",
    "            x0 (int): integer state to begin sampling\n",
    "            num_samples (int): number of proposal x* generated\n",
    "            burnin (int): number of samples to throw away before accepting first sample\n",
    "            lag (int): number of samples to throw away in-between accepting samples\n",
    "        \"\"\"\n",
    "        # uses arbitrary x_func for MH sampling\n",
    "        super().__init__()\n",
    "        self.distribution = {}\n",
    "        self.samples = num_samples\n",
    "        self.list = []\n",
    "        self.nn_output = {}\n",
    "\n",
    "        self.N = N\n",
    "        self.model = model\n",
    "        self.output_to_psi = output_to_psi\n",
    "        self.x_func = x_func\n",
    "        self.x0 = x0\n",
    "        self.num_samples = num_samples\n",
    "        self.burnin = burnin\n",
    "        self.lag = lag\n",
    "        self.chains = chains # note any of these could possibly be modified by a client\n",
    "\n",
    "        self.forwards = 0\n",
    "        self.times = {'forwards':0, 'x_func':0, 'gen_samples':0, 'convert_samples': 0, 'output_to_psi':0, 'calc_ratio':0, 'modifications':0}\n",
    "        self.gen_states = 0\n",
    "\n",
    "        if new or chains > 1:\n",
    "            num_uniform = burnin * chains + num_samples * (lag + 1)\n",
    "            self.rand_uniform = torch.rand(num_uniform)\n",
    "        self.index = 0\n",
    "        if chains == 1 and isinstance(x0, int):\n",
    "            if not new:\n",
    "                self._init_single_chain()\n",
    "            else:\n",
    "                self._init_single_chain_new()\n",
    "        elif len(x0) == chains:\n",
    "            self._init_multi_chain()\n",
    "        else:\n",
    "            del self.index\n",
    "            raise Exception('invalid initial values or number of chains')\n",
    "        del self.index\n",
    "    \n",
    "    \n",
    "    def _init_single_chain(self):\n",
    "        def psi(x):\n",
    "            tens = torch.tensor([utils.generate_state_array(x, self.N)], dtype = torch.float32)\n",
    "            nn_output = self.model(tens)\n",
    "            self.forwards += 1\n",
    "            return self.output_to_psi(nn_output)[0], nn_output[0]\n",
    "        num_uniform = self.burnin + self.num_samples * (self.lag + 1)\n",
    "        rand_uniform = npr.uniform(0, 1, num_uniform)\n",
    "        index = 0\n",
    "\n",
    "        x = self.x0\n",
    "\n",
    "        psi_val, nn_val = psi(x)\n",
    "        self.values[x] = psi_val\n",
    "        self.nn_output[x] = nn_val\n",
    "\n",
    "        for _ in range(self.burnin):\n",
    "            new_x = self.x_func(x)\n",
    "            new_psi_val = self.values[new_x] if new_x in self.values else psi(new_x)[0]\n",
    "            ratio = abs(new_psi_val) ** 2 / abs(psi_val) ** 2\n",
    "            print(x, rand_uniform[index])\n",
    "            if ratio > 1 or ratio > rand_uniform[index]:\n",
    "                x = new_x\n",
    "                psi_val = new_psi_val\n",
    "            index += 1\n",
    "        for _ in range(self.num_samples):\n",
    "            for _ in range(self.lag):\n",
    "                new_x = self.x_func(x)\n",
    "                new_psi_val = self.values[new_x] if new_x in self.values else psi(new_x)[0]\n",
    "                ratio = abs(new_psi_val) ** 2 / abs(psi_val) ** 2\n",
    "                if ratio > 1 or ratio > rand_uniform[index]:\n",
    "                    x = new_x\n",
    "                    psi_val = new_psi_val\n",
    "                index += 1\n",
    "            new_x = self.x_func(x)\n",
    "            if new_x in self.values: new_psi_val, new_nn_val = self.values[new_x], self.nn_output[new_x]\n",
    "            else: new_psi_val, new_nn_val = psi(new_x)\n",
    "            ratio = abs(new_psi_val) ** 2 / abs(psi_val) ** 2\n",
    "            if ratio > 1 or ratio > rand_uniform[index]:\n",
    "                self.distribution[new_x] = self.distribution.get(new_x, 0) + 1\n",
    "                self.list.append(new_x)\n",
    "                x = new_x \n",
    "                psi_val = new_psi_val \n",
    "            else: \n",
    "                self.distribution[x] = self.distribution.get(x, 0) + 1\n",
    "                self.list.append(x)\n",
    "            self.values[new_x] = new_psi_val\n",
    "            self.nn_output[new_x] = new_nn_val\n",
    "            index += 1\n",
    "\n",
    "    def _init_single_chain_new(self):\n",
    "        def psi(x):\n",
    "            start = time.time()\n",
    "            arr = [utils.generate_state_array(x, self.N)]\n",
    "            self.times['gen_samples'] += time.time() - start\n",
    "\n",
    "            start = time.time()\n",
    "            tens = torch.tensor(arr, dtype = torch.float32)\n",
    "            self.times['convert_samples'] += time.time() - start\n",
    "            \n",
    "            self.gen_states += 1\n",
    "            start = time.time()\n",
    "            nn_output = self.model(tens)\n",
    "            self.times['forwards'] += time.time() - start\n",
    "            self.forwards += 1\n",
    "            return self.output_to_psi(nn_output)[0], nn_output[0]\n",
    "\n",
    "        x = self.x0\n",
    "\n",
    "        def run_single_sample(modify = False):\n",
    "            nonlocal x\n",
    "            nonlocal psi_val\n",
    "            new_x = self.x_func(x)\n",
    "            if new_x in self.values: new_psi_val, new_nn_val = self.values[new_x], self.nn_output[new_x]\n",
    "            else: new_psi_val, new_nn_val = psi(new_x)\n",
    "            ratio = abs(new_psi_val) ** 2 / abs(psi_val) ** 2\n",
    "            if ratio > 1 or ratio > self.rand_uniform[self.index]:\n",
    "                if modify:\n",
    "                    self.distribution[new_x] = self.distribution.get(new_x, 0) + 1\n",
    "                    self.list.append(new_x)\n",
    "                x = new_x \n",
    "                psi_val = new_psi_val \n",
    "            elif modify: \n",
    "                self.distribution[x] = self.distribution.get(x, 0) + 1\n",
    "                self.list.append(x)\n",
    "            self.values[new_x] = new_psi_val\n",
    "            self.nn_output[new_x] = new_nn_val\n",
    "            self.index += 1\n",
    "            \n",
    "\n",
    "        psi_val, nn_val = psi(x)\n",
    "        self.values[x] = psi_val\n",
    "        self.nn_output[x] = nn_val\n",
    "        print('here', x)\n",
    "        for _ in range(self.burnin):\n",
    "            run_single_sample(modify = False)\n",
    "        for _ in range(self.num_samples):\n",
    "            for _ in range(self.lag):\n",
    "                run_single_sample(modify = False)\n",
    "            run_single_sample(modify = True)\n",
    "\n",
    "    def _init_multi_chain(self):\n",
    "        def psi(xs):\n",
    "            self.gen_states += len(xs)\n",
    "            start = time.time()\n",
    "            # tens = utils.generate_input_samples(self.N, xs)\n",
    "            tens = generate_input_samples(xs, self.N)\n",
    "            # arr = [utils.generate_state_array(x, self.N) for x in xs]\n",
    "            self.times['gen_samples'] += time.time() - start\n",
    "\n",
    "            # start = time.time()\n",
    "            # tens = torch.tensor(arr, dtype = torch.float32)\n",
    "            # self.times['convert_samples'] += time.time() - start\n",
    "\n",
    "            start = time.time()\n",
    "            nn_output = self.model(tens)\n",
    "            self.times['forwards'] += time.time() - start\n",
    "            self.forwards += 1\n",
    "\n",
    "            start = time.time()\n",
    "            res = self.output_to_psi(nn_output)\n",
    "            self.times['output_to_psi'] += time.time() - start\n",
    "            return res, nn_output\n",
    "\n",
    "        xs = self.x0[:]\n",
    "        psi_vals, nn_vals = psi(xs)\n",
    "        for i, x in enumerate(xs):\n",
    "            self.values[x] = psi_vals[i]\n",
    "            self.nn_output[x] = nn_vals[i]\n",
    "        \n",
    "        for _ in range(self.burnin):\n",
    "            self._run_single_chained_sample(xs, psi_vals, self.x_func, psi, modify = False)\n",
    "        num_iters = self.num_samples // self.chains\n",
    "        remainder = self.num_samples % self.chains\n",
    "        for c in range(num_iters):\n",
    "            for _ in range(self.lag):\n",
    "                self._run_single_chained_sample(xs, psi_vals, self.x_func, psi, modify = False)\n",
    "            self._run_single_chained_sample(xs, psi_vals, self.x_func, psi, modify = True)\n",
    "        if remainder != 0:\n",
    "            xs = xs[:remainder]\n",
    "            psi_vals = psi(xs)[0]\n",
    "            self._run_single_chained_sample(xs, psi_vals, self.x_func, psi, modify = True)\n",
    "    \n",
    "    def _run_single_chained_sample(self, xs, psis, x_func, psi_function, modify = False):\n",
    "        start = time.time()\n",
    "        # new_xs = torch.tensor([x_func(x) for x in xs])\n",
    "        new_xs = bitflip_batch(xs, self.N, 1)\n",
    "        self.times['x_func'] += time.time() - start\n",
    "\n",
    "        new_psi_vals, new_nn_vals = psi_function(new_xs)\n",
    "        start = time.time()\n",
    "        ratios = torch.abs(new_psi_vals) ** 2 / torch.abs(psis) ** 2\n",
    "        self.times['calc_ratio'] += time.time() - start\n",
    "\n",
    "        start = time.time()\n",
    "        accept_mask = (ratios > 1) | (ratios > self.rand_uniform[self.index : self.index + len(xs)])\n",
    "        xs[accept_mask] = new_xs[accept_mask]\n",
    "        psis[accept_mask] = new_psi_vals[accept_mask]\n",
    "\n",
    "        if modify:\n",
    "            accepted = new_xs[accept_mask]\n",
    "            rejected = xs[~accept_mask]\n",
    "\n",
    "            for x in accepted.tolist():\n",
    "                self.distribution[x] = self.distribution.get(x, 0) + 1\n",
    "                self.list.append(x)\n",
    "\n",
    "            for x in rejected.tolist():\n",
    "                self.distribution[x] = self.distribution.get(x, 0) + 1\n",
    "                self.list.append(x)\n",
    "\n",
    "        for x, val, nn in zip(new_xs.tolist(), new_psi_vals.tolist(), new_nn_vals.tolist()):\n",
    "            self.values[x] = val\n",
    "            self.nn_output[x] = nn\n",
    "        \n",
    "        self.index += len(xs)\n",
    "\n",
    "        # for i, (x, new_x, new_psi_val, new_nn_val, ratio) in enumerate(zip(xs, new_xs, new_psi_vals, new_nn_vals, ratios)):\n",
    "        #     # start = time.time()\n",
    "        #     # ratio = abs(new_psi_val) ** 2 / abs(psis[i]) ** 2\n",
    "        #     # self.times['calc_ratio'] += time.time() - start\n",
    "            \n",
    "        #     if ratio > 1 or ratio > self.rand_uniform[self.index]:\n",
    "        #         if modify:\n",
    "        #             # input_samples[i] = torch.tensor(utils.generate_state_array(new_xs[i], self.N), dtype = torch.int32)\n",
    "        #             self.distribution[new_x] = self.distribution.get(new_xs[i], 0) + 1\n",
    "        #             self.list.append(new_x.item())\n",
    "        #         xs[i] = new_x\n",
    "        #         psis[i] = new_psi_val\n",
    "        #     elif modify:\n",
    "        #         self.distribution[x] = self.distribution.get(x, 0) + 1\n",
    "        #         self.list.append(x.item())\n",
    "        #     self.values[new_x] = new_psi_val\n",
    "        #     self.nn_output[new_x] = new_nn_val\n",
    "        #     self.index += 1\n",
    "        self.times['modifications'] += time.time() - start\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974185ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "npr.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc823e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "layers = []\n",
    "layers.append(nn.Linear(N, 32))\n",
    "for _ in range(2):\n",
    "    layers.append(nn.Linear(32, 32))\n",
    "    layers.append(nn.SELU())\n",
    "layers.append(nn.Linear(32, 2))\n",
    "mlp_model = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ae6486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6973, 0.1897],\n",
      "        [0.5673, 0.7153]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.rand((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac856a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "print(utils.bitflip_x(0, 10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7d6a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8442657485810173\n",
      "512 0.8579456176227568\n"
     ]
    }
   ],
   "source": [
    "state_old = MHNeuralState(N, mlp_model, utils.log_amp_phase, lambda x: utils.bitflip_x(x, N, 1), 0, 20, burnin = 2, lag = 1, chains = 1, new = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "004590b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[712, 717, 741, 245, 165, 165, 189, 429, 437, 277, 308, 278, 798, 831, 828, 808, 813, 801, 928, 384]\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(state_old.list) # the results are the same for new and old method using the same seed, check parallel_MH_2_seeding.ipynb\n",
    "print(state_old.forwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22d3b028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here 0\n"
     ]
    }
   ],
   "source": [
    "state_new = MHNeuralState(N, mlp_model, utils.log_amp_phase, lambda x: utils.bitflip_x(x, N, 1), 0, 20, burnin = 2, lag = 1, chains = 1, new = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68bea4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 644, 644, 648, 666, 158, 140, 460, 448, 449, 384, 456, 192, 192, 204, 201, 201, 449, 197, 221]\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(state_new.list)\n",
    "print(state_new.forwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b8790d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = 10\n",
    "state_chained = MHNeuralState(N, mlp_model, utils.log_amp_phase, lambda x: utils.bitflip_x(x, N, 1), torch.zeros(chains, dtype = torch.long), 200, burnin = 50, lag = 5, chains = chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae7f6d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[946, 835, 658, 390, 314, 596, 681, 10, 814, 497, 900, 1016, 269, 691, 912, 360, 293, 947, 634, 1013, 612, 755, 951, 931, 344, 869, 189, 1015, 120, 893, 652, 656, 915, 160, 784, 549, 804, 863, 548, 870, 652, 939, 1008, 978, 14, 565, 937, 86, 622, 238, 969, 770, 1000, 962, 190, 290, 697, 141, 102, 592, 853, 866, 332, 354, 442, 944, 209, 724, 311, 452, 797, 98, 469, 170, 272, 768, 154, 217, 937, 807, 536, 614, 449, 166, 212, 786, 450, 443, 231, 305, 572, 626, 106, 176, 222, 863, 450, 205, 741, 317, 76, 747, 108, 188, 444, 295, 1000, 653, 255, 943, 362, 710, 840, 302, 788, 419, 198, 695, 228, 674, 818, 218, 338, 76, 263, 695, 907, 319, 46, 514, 217, 384, 239, 768, 855, 462, 795, 141, 420, 2, 432, 157, 40, 457, 962, 856, 498, 30, 605, 390, 441, 214, 810, 922, 775, 90, 624, 18, 792, 478, 566, 446, 130, 551, 154, 626, 771, 177, 228, 385, 920, 604, 935, 928, 939, 154, 566, 807, 385, 416, 784, 110, 803, 813, 894, 175, 309, 839, 193, 100, 920, 100, 446, 588, 924, 535, 563, 903, 644, 240]\n",
      "171\n"
     ]
    }
   ],
   "source": [
    "print(state_chained.list)\n",
    "print(state_chained.forwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ede9de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "layers = []\n",
    "layers.append(nn.Linear(N, 32))\n",
    "for _ in range(2):\n",
    "    layers.append(nn.Linear(32, 32))\n",
    "    layers.append(nn.SELU())\n",
    "layers.append(nn.Linear(32, 2))\n",
    "larger_model = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e04d3c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here 0\n",
      "10.272404909133911\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "state_old = MHNeuralState(N, larger_model, utils.log_amp_phase, lambda x: utils.bitflip_x(x, N, 1), 0, 2000, burnin = 50, lag = 10, chains = 1, new = True)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8251025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21186\n",
      "{'forwards': 4.562281370162964, 'x_func': 0, 'gen_samples': 0.1672666072845459, 'convert_samples': 0.3215444087982178, 'output_to_psi': 0, 'calc_ratio': 0, 'modifications': 0}\n",
      "21186\n"
     ]
    }
   ],
   "source": [
    "print(state_old.forwards)\n",
    "print(state_old.times)\n",
    "print(state_old.gen_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e862eb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3077776432037354\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "chains = 50\n",
    "state_chained = MHNeuralState(N, larger_model, utils.log_amp_phase, lambda x: utils.bitflip_x(x, N, 1), torch.tensor([0] * chains, dtype = torch.long), 2000, burnin = 50, lag = 10, chains = chains)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a48d3f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491\n",
      "{'forwards': 1.074425220489502, 'x_func': 0.02244877815246582, 'gen_samples': 0.03716015815734863, 'convert_samples': 0, 'output_to_psi': 0.05267906188964844, 'calc_ratio': 0.04322314262390137, 'modifications': 0.07052111625671387}\n",
      "24550\n"
     ]
    }
   ],
   "source": [
    "print(state_chained.forwards)\n",
    "print(state_chained.times)\n",
    "print(state_chained.gen_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "babed72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "import kan\n",
    "N = 10\n",
    "kan_model = kan.KAN([N, N, 2], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ec67098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:813: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:823: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:824: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:825: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here 0\n",
      "83.54823136329651\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "state_old = MHNeuralState(N, kan_model, utils.log_amp_phase, lambda x: utils.bitflip_x(x, N, 1), 0, 1000, burnin = 50, lag = 10, chains = 1, new = True)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71a2c1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "{'forwards': 80.92080807685852, 'x_func': 0, 'gen_samples': 0.0030183792114257812, 'convert_samples': 0.019258737564086914, 'output_to_psi': 0, 'calc_ratio': 0, 'modifications': 0}\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "print(state_old.forwards)\n",
    "print(state_old.times)\n",
    "print(state_old.gen_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b99e748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3077776432037354\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "chains = 50\n",
    "state_chained = MHNeuralState(N, kan_model, utils.log_amp_phase, lambda x: utils.bitflip_x(x, N, 1), torch.tensor([0] * chains, dtype = torch.long), 1000, burnin = 50, lag = 10, chains = chains)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d298a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491\n",
      "{'forwards': 1.074425220489502, 'x_func': 0.02244877815246582, 'gen_samples': 0.03716015815734863, 'convert_samples': 0, 'output_to_psi': 0.05267906188964844, 'calc_ratio': 0.04322314262390137, 'modifications': 0.07052111625671387}\n",
      "24550\n"
     ]
    }
   ],
   "source": [
    "print(state_chained.forwards)\n",
    "print(state_chained.times)\n",
    "print(state_chained.gen_states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
