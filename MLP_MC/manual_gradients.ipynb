{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries import lib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as npr\n",
    "import random\n",
    "\n",
    "class SparseStateVector:\n",
    "    \"\"\"\n",
    "    Container class for dictionary (self.values) with keys of integer states\n",
    "    and values being complex amplitude of psi\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.values = {}\n",
    "        self.normalized = False\n",
    "\n",
    "    def TFIM_multiply(psi, N, J, Gamma):\n",
    "        \"\"\"\n",
    "        Returns new sparse vector representing H|psi>\n",
    "        \"\"\"\n",
    "        prod = SparseStateVector()\n",
    "        for state in psi.values:\n",
    "            jtotal = 0\n",
    "            for site in range(N - 1):\n",
    "                jtotal += J if ((state >> site) ^ (state >> site + 1)) & 1 else -J\n",
    "            jtotal += J if ((state >> (N - 1)) ^ (state >> 0)) & 1 else -J \n",
    "            prod.values[state] = jtotal * psi.values[state]\n",
    "        \n",
    "        for state in psi.values:\n",
    "            for site in range(N):\n",
    "                flipped_state = state ^ (1 << site)\n",
    "                prod.values[flipped_state] = prod.values.get(flipped_state, 0) - Gamma * psi.values[state]\n",
    "        return prod\n",
    "\n",
    "    def inner_product(v1, v2):\n",
    "        \"\"\"\n",
    "        Returns <v1|v2> for two SparseStateVectors\n",
    "        \"\"\"\n",
    "        prod = 0\n",
    "        for s in v1.values:\n",
    "            if s in v2.values:\n",
    "                prod += torch.conj(v1.values[s]) * v2.values[s]\n",
    "        return prod\n",
    "\n",
    "    def TFIM_expectation_from_sparse(psi, N, J, Gamma):\n",
    "        \"\"\"\n",
    "        Returns <psi|H|psi>/<psi|psi> for SparseStateVector psi\n",
    "        \"\"\"\n",
    "        # do H|psi> then <psi| (H|psi>)\n",
    "        hpsi = SparseStateVector.TFIM_multiply(psi, N, J, Gamma)\n",
    "        exp = SparseStateVector.inner_product(psi, hpsi)\n",
    "        if not psi.normalized:\n",
    "            mag2 = SparseStateVector.inner_product(psi, psi)\n",
    "            return (exp / mag2).real\n",
    "        return exp.real\n",
    "\n",
    "    def normalize(self):\n",
    "        \"\"\"\n",
    "        Normalizes values\n",
    "        \"\"\"\n",
    "        mag = sum(abs(self.values[s]) ** 2 for s in self.values) ** 0.5\n",
    "        for s in self.values:\n",
    "            self.values[s] = self.values[s] / mag\n",
    "        self.normalized = True\n",
    "\n",
    "    def to_prob_distribution(self, N):\n",
    "        \"\"\"\n",
    "        Returns 1D list representing real probability distribution\n",
    "        \"\"\"\n",
    "        if not self.normalized:\n",
    "            mag2 = sum(abs(self.values[s]) ** 2 for s in self.values)\n",
    "            return [(abs(self.values.get(s, 0)) ** 2 / mag2).item() for s in range(0, 2 ** N)]\n",
    "        return [abs(self.values.get(s, 0)) ** 2 for s in range(0, 2 ** N)]\n",
    "    \n",
    "    def to_dense_vector(self, N):\n",
    "        \"\"\"\n",
    "        Returns 1D list of dense representation\n",
    "        \"\"\"\n",
    "        if not self.normalized:\n",
    "            mag = sum(abs(self.values[s]) ** 2 for s in self.values) ** 0.5\n",
    "            return [(self.values.get(s, 0) / mag).item() for s in range(0, 2 ** N)]\n",
    "        return [self.values.get(s, 0).item() for s in range(0, 2 ** N)]\n",
    "\n",
    "class UniformNeuralState(SparseStateVector):\n",
    "    def __init__(self, N, model, output_to_psi, num_samples):\n",
    "        \"\"\"\n",
    "        Initializes sparse vector values\n",
    "\n",
    "        Args:\n",
    "            N (int): number of qubits\n",
    "            model: torch model representing psi(x), which returns complex amplitude given integer state\n",
    "            output_to_psi (function): takes in output of model to compute complex amplitude\n",
    "            num_samples (int): number of unique integer samples to take\n",
    "            informed (bool): whether to guarantee sample first and last states\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.samples = num_samples\n",
    "        self.distribution = {}\n",
    "        self.list = []\n",
    "        self.nn_output = {}\n",
    "        def psi(x):\n",
    "            tens = torch.tensor([lib.generate_state_array(x, N)], dtype = torch.float32)\n",
    "            nn_output = model(tens)\n",
    "            return output_to_psi(nn_output)[0], nn_output[0]\n",
    "        if num_samples >= 2 ** N:\n",
    "            for state in range(2 ** N):\n",
    "                self.distribution[state] = 1\n",
    "                self.list.append(state)\n",
    "                self.values[state], self.nn_output[state] = psi(state)\n",
    "        else:\n",
    "            sampled_states = set()\n",
    "            for _ in range(num_samples):\n",
    "                x = random.getrandbits(N)\n",
    "                while x in sampled_states:\n",
    "                    x = random.getrandbits(N)\n",
    "                sampled_states.add(x)\n",
    "                self.distribution[x] = self.distribution.get(x, 0) + 1\n",
    "                self.list.append(x)\n",
    "            for state in sampled_states:\n",
    "                self.values[state], self.nn_output[state] = psi(state)\n",
    "\n",
    "class MHNeuralState(SparseStateVector):\n",
    "    def __init__(self, N, model, output_to_psi, x_func, x0, num_samples, burnin = 0, lag = 0):\n",
    "        \"\"\"\n",
    "        Initializes distribution of samples and vector values\n",
    "\n",
    "        Args:\n",
    "            N (int): number of qubits\n",
    "            model: torch model representing psi(x), which returns complex amplitude given integer state\n",
    "            output_to_psi (function): takes in output of model to compute complex amplitude\n",
    "            x_func (function): takes in state x and generates proposal x*\n",
    "            x0 (int): intger state to begin sampling\n",
    "            num_samples (int): number of proposal x* generated\n",
    "            burnin (int): number of samples to throw away before accepting first sample\n",
    "            lag (int): number of samples to throw away in-between accepting samples\n",
    "            informed (bool): whether to guarantee sample first and last states\n",
    "        \"\"\"\n",
    "        # uses arbitrary x_func for MH sampling\n",
    "        super().__init__()\n",
    "        self.distribution = {}\n",
    "        self.list = []\n",
    "        self.nn_output = {}\n",
    "        self.samples = num_samples\n",
    "        def psi(x):\n",
    "            tens = torch.tensor([lib.generate_state_array(x, N)], dtype = torch.float32)\n",
    "            nn_output = model(tens)\n",
    "            return output_to_psi(nn_output)[0], nn_output[0]\n",
    "        num_uniform = burnin + num_samples * (lag + 1)\n",
    "        rand_uniform = npr.uniform(0, 1, num_uniform)\n",
    "        index = 0\n",
    "\n",
    "        x = x0\n",
    "        psi_val, nn_val = psi(x)\n",
    "        self.values[x] = psi_val\n",
    "        self.nn_output[x] = nn_val\n",
    "        for _ in range(burnin):\n",
    "            new_x = x_func(x)\n",
    "            new_psi_val = self.values[new_x] if new_x in self.values else psi(new_x)[0]\n",
    "            ratio = abs(new_psi_val) ** 2 / abs(psi_val) ** 2\n",
    "            if ratio > 1 or ratio > rand_uniform[index]:\n",
    "                x = new_x\n",
    "                psi_val = new_psi_val\n",
    "            index += 1\n",
    "        for _ in range(num_samples):\n",
    "            for _ in range(lag):\n",
    "                new_x = x_func(x)\n",
    "                new_psi_val = self.values[new_x] if new_x in self.values else psi(new_x)[0]\n",
    "                ratio = abs(new_psi_val) ** 2 / abs(psi_val) ** 2\n",
    "                if ratio > 1 or ratio > rand_uniform[index]:\n",
    "                    x = new_x\n",
    "                    psi_val = new_psi_val\n",
    "                index += 1\n",
    "            new_x = x_func(x)\n",
    "            if new_x in self.values: new_psi_val, new_nn_val = self.values[new_x], self.nn_output[new_x]\n",
    "            else: new_psi_val, new_nn_val = psi(new_x)\n",
    "            ratio = abs(new_psi_val) ** 2 / abs(psi_val) ** 2\n",
    "            if ratio > 1 or ratio > rand_uniform[index]:\n",
    "                self.distribution[new_x] = self.distribution.get(new_x, 0) + 1\n",
    "                self.list.append(new_x)\n",
    "                x = new_x \n",
    "                psi_val = new_psi_val \n",
    "            else: \n",
    "                self.distribution[x] = self.distribution.get(x, 0) + 1\n",
    "                self.list.append(x)\n",
    "            self.values[new_x] = new_psi_val\n",
    "            self.nn_output[new_x] = new_nn_val\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_amp_phase(nn_output):\n",
    "    return torch.exp(nn_output[:, 0] + 1.j * nn_output[:, 1])\n",
    "def bitflip_x(x, N, flips):\n",
    "    new_x = x\n",
    "    for _ in range(flips):\n",
    "        new_x = x ^ (1 << npr.randint(0, N))\n",
    "    return new_x\n",
    "# only for nn_output = (log(amp), phase)\n",
    "def generate_eloc_list(sampled_vector, N, J, Gamma, model):\n",
    "    nn_output_calcs = {}\n",
    "    def model_to_output(x):\n",
    "        if x in sampled_vector.nn_output:\n",
    "            return sampled_vector.nn_output[x]\n",
    "        if x in nn_output_calcs:\n",
    "            return nn_output_calcs[x]\n",
    "        tens = torch.tensor([lib.generate_state_array(x, N)], dtype = torch.float32)\n",
    "        output = model(tens)[0]\n",
    "        nn_output_calcs[x] = output\n",
    "        return output\n",
    "\n",
    "    eloc_values = []\n",
    "    for basis_state in sampled_vector.list:\n",
    "        eloc = 0\n",
    "        output = model_to_output(basis_state)\n",
    "        for adjacency in lib.generate_adjacencies(basis_state, N):\n",
    "            output_prime = model_to_output(adjacency)\n",
    "            eloc += lib.calc_H_elem(N, J, Gamma, basis_state, adjacency) * torch.exp(output_prime[0] - output[0] + 1.j * 2 * np.pi * (output_prime[1] - output[1]))\n",
    "        # eloc += lib.calc_H_elem(N, J, Gamma, basis_state, basis_state)\n",
    "        eloc_values.append(eloc)\n",
    "    return eloc_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_gradients(sampled_vector, N, J, Gamma, model): # also only for log(amp), phase\n",
    "    nn_output_calcs = {}\n",
    "    def model_to_output(x):\n",
    "        if x in sampled_vector.nn_output:\n",
    "            return sampled_vector.nn_output[x]\n",
    "        if x in nn_output_calcs:\n",
    "            return nn_output_calcs[x]\n",
    "        tens = torch.tensor([lib.generate_state_array(x, N)], dtype = torch.float32)\n",
    "        output = model(tens)[0]\n",
    "        nn_output_calcs[x] = output\n",
    "        return output\n",
    "    def output_to_log(x):\n",
    "        return x[0] + 1.j * x[1]\n",
    "\n",
    "    params = [n for n in model.parameters()]\n",
    "    energy = # lib.TFIM_expectation_using_locals(sampled_vector, N, J, Gamma, model, log_amp_phase)\n",
    "    for i in range(len(params)):\n",
    "        p = params[i]\n",
    "        grad = torch.zeros(p.shape)\n",
    "        tot = 0\n",
    "        for basis_state in sampled_vector.list:\n",
    "            for adjacency in lib.generate_adjacencies(basis_state, N):\n",
    "                log_psi = output_to_log(model_to_output(basis_state))\n",
    "                log_psi_p = output_to_log(model_to_output(adjacency))\n",
    "                tot += lib.calc_H_elem(N, J, Gamma, basis_state, adjacency) * torch.exp(log_psi_p - log_psi).detach()\n",
    "        avg = tot / len(sampled_vector.list)\n",
    "\n",
    "        for basis_state in sampled_vector.distribution:\n",
    "            for adjacency in lib.generate_adjacencies(basis_state, N):\n",
    "                log_psi = output_to_log(model_to_output(basis_state))\n",
    "                log_psi_p = output_to_log(model_to_output(adjacency))\n",
    "                \n",
    "                log_psi.conj().real.backward(retain_graph=True)\n",
    "                grad_re_log = p.grad.clone()\n",
    "                log_psi.conj().imag.backward(retain_graph=True)\n",
    "                grad_im_log = p.grad.clone()\n",
    "\n",
    "                mag_psi = abs(torch.exp(log_psi)).detach()\n",
    "                H_psi_over_psi = lib.calc_H_elem(N, J, Gamma, basis_state, adjacency) * torch.exp(log_psi_p - log_psi).detach() - avg\n",
    "                grad += mag_psi ** 2 * (grad_re_log * H_psi_over_psi.real - grad_im_log * H_psi_over_psi.imag)\n",
    "\n",
    "                # print(log_psi, log_psi_p, grad_re_log, grad_im_log, mag_psi, psi_over_psi)\n",
    "        p.grad = grad\n",
    "        # psi_times_psi = SparseStateVector.inner_product(sampled_vector, sampled_vector).real\n",
    "        #sum(abs(torch.exp(output_to_log(model_to_output(basis_state)))) ** 2 for basis_state in sampled_vector.distribution)\n",
    "        # torch.log(psi_times_psi).backward(retain_graph=True)\n",
    "        # grad_log_psi_psi = p.grad.clone()\n",
    "\n",
    "        # p.grad = grad / psi_times_psi.detach() - grad_log_psi_psi * energy.detach()\n",
    "    return energy\n",
    "\n",
    "def update_gradients(model, lr):\n",
    "    with torch.no_grad():\n",
    "        for p in model.parameters():\n",
    "            p += lr * p.grad \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 6; J = 1; Gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "layers.append(nn.Linear(N, 32))\n",
    "for _ in range(2):\n",
    "    layers.append(nn.Linear(32, 32))\n",
    "    layers.append(nn.SELU())\n",
    "layers.append(nn.Linear(32, 2))\n",
    "model = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1308,  0.2979, -0.2408, -0.2620,  0.1666,  0.0668],\n",
      "        [-0.3188, -0.1433, -0.2242,  0.2391, -0.1207,  0.3539],\n",
      "        [-0.4079, -0.2942,  0.1733, -0.2653,  0.0198,  0.0406],\n",
      "        [ 0.3843,  0.2710, -0.2725,  0.1489,  0.1490, -0.1666],\n",
      "        [ 0.3209,  0.2624, -0.0622, -0.1468,  0.3634,  0.3543],\n",
      "        [ 0.2540,  0.3930,  0.1019, -0.2897, -0.3592,  0.3650],\n",
      "        [-0.3040, -0.3116, -0.1106, -0.3790,  0.2897, -0.2073],\n",
      "        [ 0.0252, -0.0414,  0.0143, -0.3691, -0.0200,  0.1184],\n",
      "        [-0.3694,  0.3216,  0.0432,  0.3746, -0.0206, -0.3100],\n",
      "        [ 0.2689, -0.3660, -0.0091, -0.2488,  0.1504,  0.0083],\n",
      "        [ 0.1293, -0.1399,  0.0953,  0.1167, -0.1892,  0.2592],\n",
      "        [-0.2867,  0.0284, -0.2861, -0.2635,  0.2299, -0.2762],\n",
      "        [-0.2474, -0.0844,  0.0051,  0.0792, -0.1043,  0.0739],\n",
      "        [-0.1683, -0.2008, -0.0345,  0.1325,  0.1517,  0.0028],\n",
      "        [-0.2652, -0.1139, -0.1074, -0.3011,  0.0672,  0.3861],\n",
      "        [-0.2173, -0.2383,  0.1135, -0.1898, -0.1297, -0.0576],\n",
      "        [-0.0109,  0.0961,  0.3566, -0.2249, -0.0442, -0.0066],\n",
      "        [-0.0022, -0.3215, -0.0680,  0.3766,  0.0562,  0.3207],\n",
      "        [-0.1914,  0.2027, -0.1845,  0.0841, -0.0107,  0.0949],\n",
      "        [-0.3486, -0.1919, -0.4076, -0.3099, -0.1343, -0.2002],\n",
      "        [ 0.2348, -0.0160, -0.0945,  0.3534,  0.3210, -0.1791],\n",
      "        [ 0.0960,  0.3533,  0.3426,  0.1120, -0.1432, -0.2615],\n",
      "        [ 0.1835,  0.3854,  0.2590, -0.3512,  0.0580, -0.0767],\n",
      "        [ 0.2327,  0.3005,  0.2648, -0.4034, -0.2119,  0.3860],\n",
      "        [-0.2428,  0.3999,  0.0559, -0.3517, -0.2583,  0.3457],\n",
      "        [-0.0573,  0.1626, -0.3308,  0.0987, -0.0930,  0.2951],\n",
      "        [ 0.0670,  0.2498, -0.0183,  0.3354, -0.2776, -0.1871],\n",
      "        [-0.2130, -0.1755,  0.3293,  0.3931,  0.2831, -0.0702],\n",
      "        [ 0.3743,  0.3008,  0.2079,  0.0589,  0.4078, -0.3072],\n",
      "        [-0.0197,  0.1157, -0.3912, -0.2291, -0.1426, -0.2329],\n",
      "        [-0.1104, -0.3757,  0.3091, -0.1280, -0.2225,  0.0660],\n",
      "        [-0.1602,  0.2083,  0.0507,  0.0422,  0.1054, -0.2247]],\n",
      "       requires_grad=True)\n",
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "params = [n for n in model.parameters()]\n",
    "print(params[0])\n",
    "params[0] = torch.zeros(params[0].shape)\n",
    "print(params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "data_rate = 1\n",
    "num_samples = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(-0.5887, grad_fn=<SelectBackward0>)\n",
      "1 tensor(-0.5444, grad_fn=<SelectBackward0>)\n",
      "2 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "3 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "4 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "5 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "6 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "7 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "8 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "9 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "10 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "11 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "12 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "13 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "14 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "15 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "16 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "17 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "18 tensor(nan, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m mh_state \u001b[38;5;241m=\u001b[39m UniformNeuralState(N, model, log_amp_phase, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m N)\n\u001b[0;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 8\u001b[0m energy \u001b[38;5;241m=\u001b[39m \u001b[43mset_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmh_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# energy = lib.TFIM_expectation_using_locals(mh_state, N, J, Gamma, model, log_amp_phase)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[11], line 40\u001b[0m, in \u001b[0;36mset_gradients\u001b[1;34m(sampled_vector, N, J, Gamma, model)\u001b[0m\n\u001b[0;32m     38\u001b[0m         mag_psi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(torch\u001b[38;5;241m.\u001b[39mexp(log_psi))\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m     39\u001b[0m         H_psi_over_psi \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mcalc_H_elem(N, J, Gamma, basis_state, adjacency) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(log_psi_p \u001b[38;5;241m-\u001b[39m log_psi)\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m-\u001b[39m avg\n\u001b[1;32m---> 40\u001b[0m         grad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mag_psi \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (grad_re_log \u001b[38;5;241m*\u001b[39m H_psi_over_psi\u001b[38;5;241m.\u001b[39mreal \u001b[38;5;241m-\u001b[39m grad_im_log \u001b[38;5;241m*\u001b[39m H_psi_over_psi\u001b[38;5;241m.\u001b[39mimag)\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;66;03m# print(log_psi, log_psi_p, grad_re_log, grad_im_log, mag_psi, psi_over_psi)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m grad\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = []\n",
    "energy_data = []\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-5)\n",
    "for epoch in range(num_epochs):\n",
    "    # mh_state = MHNeuralState(N, model, log_amp_phase, lambda x: bitflip_x(x, N, 1), 2 ** (N - 1), num_samples)\n",
    "    mh_state = UniformNeuralState(N, model, log_amp_phase, 2 ** N)\n",
    "    optimizer.zero_grad()\n",
    "    energy = set_gradients(mh_state, N, J, Gamma, model)\n",
    "    # energy = lib.TFIM_expectation_using_locals(mh_state, N, J, Gamma, model, log_amp_phase)\n",
    "    optimizer.step()\n",
    "    # update_gradients(model, 1e-5)\n",
    "    if epoch % data_rate == 0:\n",
    "        energy_data.append(energy.item().real)\n",
    "        epochs.append(epoch)\n",
    "    if epoch % 1 == 0:\n",
    "        print(epoch, energy)\n",
    "print(energy_data[-1])\n",
    "print(min(energy_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
