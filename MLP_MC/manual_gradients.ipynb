{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries import lib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as npr\n",
    "import random\n",
    "\n",
    "class SparseStateVector:\n",
    "    \"\"\"\n",
    "    Container class for dictionary (self.values) with keys of integer states\n",
    "    and values being complex amplitude of psi\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.values = {}\n",
    "        self.normalized = False\n",
    "\n",
    "    def TFIM_multiply(psi, N, J, Gamma):\n",
    "        \"\"\"\n",
    "        Returns new sparse vector representing H|psi>\n",
    "        \"\"\"\n",
    "        prod = SparseStateVector()\n",
    "        for state in psi.values:\n",
    "            jtotal = 0\n",
    "            for site in range(N - 1):\n",
    "                jtotal += J if ((state >> site) ^ (state >> site + 1)) & 1 else -J\n",
    "            jtotal += J if ((state >> (N - 1)) ^ (state >> 0)) & 1 else -J \n",
    "            prod.values[state] = jtotal * psi.values[state]\n",
    "        \n",
    "        for state in psi.values:\n",
    "            for site in range(N):\n",
    "                flipped_state = state ^ (1 << site)\n",
    "                prod.values[flipped_state] = prod.values.get(flipped_state, 0) - Gamma * psi.values[state]\n",
    "        return prod\n",
    "\n",
    "    def inner_product(v1, v2):\n",
    "        \"\"\"\n",
    "        Returns <v1|v2> for two SparseStateVectors\n",
    "        \"\"\"\n",
    "        prod = 0\n",
    "        for s in v1.values:\n",
    "            if s in v2.values:\n",
    "                prod += torch.conj(v1.values[s]) * v2.values[s]\n",
    "        return prod\n",
    "\n",
    "    def TFIM_expectation_from_sparse(psi, N, J, Gamma):\n",
    "        \"\"\"\n",
    "        Returns <psi|H|psi>/<psi|psi> for SparseStateVector psi\n",
    "        \"\"\"\n",
    "        # do H|psi> then <psi| (H|psi>)\n",
    "        hpsi = SparseStateVector.TFIM_multiply(psi, N, J, Gamma)\n",
    "        exp = SparseStateVector.inner_product(psi, hpsi)\n",
    "        if not psi.normalized:\n",
    "            mag2 = SparseStateVector.inner_product(psi, psi)\n",
    "            return (exp / mag2).real\n",
    "        return exp.real\n",
    "\n",
    "    def normalize(self):\n",
    "        \"\"\"\n",
    "        Normalizes values\n",
    "        \"\"\"\n",
    "        mag = sum(abs(self.values[s]) ** 2 for s in self.values) ** 0.5\n",
    "        for s in self.values:\n",
    "            self.values[s] = self.values[s] / mag\n",
    "        self.normalized = True\n",
    "\n",
    "    def to_prob_distribution(self, N):\n",
    "        \"\"\"\n",
    "        Returns 1D list representing real probability distribution\n",
    "        \"\"\"\n",
    "        if not self.normalized:\n",
    "            mag2 = sum(abs(self.values[s]) ** 2 for s in self.values)\n",
    "            return [(abs(self.values.get(s, 0)) ** 2 / mag2).item() for s in range(0, 2 ** N)]\n",
    "        return [abs(self.values.get(s, 0)) ** 2 for s in range(0, 2 ** N)]\n",
    "    \n",
    "    def to_dense_vector(self, N):\n",
    "        \"\"\"\n",
    "        Returns 1D list of dense representation\n",
    "        \"\"\"\n",
    "        if not self.normalized:\n",
    "            mag = sum(abs(self.values[s]) ** 2 for s in self.values) ** 0.5\n",
    "            return [(self.values.get(s, 0) / mag).item() for s in range(0, 2 ** N)]\n",
    "        return [self.values.get(s, 0).item() for s in range(0, 2 ** N)]\n",
    "\n",
    "class UniformNeuralState(SparseStateVector):\n",
    "    def __init__(self, N, model, output_to_psi, num_samples):\n",
    "        \"\"\"\n",
    "        Initializes sparse vector values\n",
    "\n",
    "        Args:\n",
    "            N (int): number of qubits\n",
    "            model: torch model representing psi(x), which returns complex amplitude given integer state\n",
    "            output_to_psi (function): takes in output of model to compute complex amplitude\n",
    "            num_samples (int): number of unique integer samples to take\n",
    "            informed (bool): whether to guarantee sample first and last states\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.samples = num_samples\n",
    "        self.distribution = {}\n",
    "        self.list = []\n",
    "        self.nn_output = {}\n",
    "        def psi(x):\n",
    "            tens = torch.tensor([lib.generate_state_array(x, N)], dtype = torch.float32)\n",
    "            nn_output = model(tens)\n",
    "            return output_to_psi(nn_output)[0], nn_output[0]\n",
    "        if num_samples >= 2 ** N:\n",
    "            for state in range(2 ** N):\n",
    "                self.distribution[state] = 1\n",
    "                self.list.append(state)\n",
    "                self.values[state], self.nn_output[state] = psi(state)\n",
    "        else:\n",
    "            sampled_states = set()\n",
    "            for _ in range(num_samples):\n",
    "                x = random.getrandbits(N)\n",
    "                while x in sampled_states:\n",
    "                    x = random.getrandbits(N)\n",
    "                sampled_states.add(x)\n",
    "                self.distribution[x] = self.distribution.get(x, 0) + 1\n",
    "                self.list.append(x)\n",
    "            for state in sampled_states:\n",
    "                self.values[state], self.nn_output[state] = psi(state)\n",
    "\n",
    "class MHNeuralState(SparseStateVector):\n",
    "    def __init__(self, N, model, output_to_psi, x_func, x0, num_samples, burnin = 0, lag = 0):\n",
    "        \"\"\"\n",
    "        Initializes distribution of samples and vector values\n",
    "\n",
    "        Args:\n",
    "            N (int): number of qubits\n",
    "            model: torch model representing psi(x), which returns complex amplitude given integer state\n",
    "            output_to_psi (function): takes in output of model to compute complex amplitude\n",
    "            x_func (function): takes in state x and generates proposal x*\n",
    "            x0 (int): intger state to begin sampling\n",
    "            num_samples (int): number of proposal x* generated\n",
    "            burnin (int): number of samples to throw away before accepting first sample\n",
    "            lag (int): number of samples to throw away in-between accepting samples\n",
    "            informed (bool): whether to guarantee sample first and last states\n",
    "        \"\"\"\n",
    "        # uses arbitrary x_func for MH sampling\n",
    "        super().__init__()\n",
    "        self.distribution = {}\n",
    "        self.list = []\n",
    "        self.nn_output = {}\n",
    "        self.samples = num_samples\n",
    "        def psi(x):\n",
    "            tens = torch.tensor([lib.generate_state_array(x, N)], dtype = torch.float32)\n",
    "            nn_output = model(tens)\n",
    "            return output_to_psi(nn_output)[0], nn_output[0]\n",
    "        num_uniform = burnin + num_samples * (lag + 1)\n",
    "        rand_uniform = npr.uniform(0, 1, num_uniform)\n",
    "        index = 0\n",
    "\n",
    "        x = x0\n",
    "        psi_val, nn_val = psi(x)\n",
    "        self.values[x] = psi_val\n",
    "        self.nn_output[x] = nn_val\n",
    "        for _ in range(burnin):\n",
    "            new_x = x_func(x)\n",
    "            new_psi_val = self.values[new_x] if new_x in self.values else psi(new_x)[0]\n",
    "            ratio = abs(new_psi_val) ** 2 / abs(psi_val) ** 2\n",
    "            if ratio > 1 or ratio > rand_uniform[index]:\n",
    "                x = new_x\n",
    "                psi_val = new_psi_val\n",
    "            index += 1\n",
    "        for _ in range(num_samples):\n",
    "            for _ in range(lag):\n",
    "                new_x = x_func(x)\n",
    "                new_psi_val = self.values[new_x] if new_x in self.values else psi(new_x)[0]\n",
    "                ratio = abs(new_psi_val) ** 2 / abs(psi_val) ** 2\n",
    "                if ratio > 1 or ratio > rand_uniform[index]:\n",
    "                    x = new_x\n",
    "                    psi_val = new_psi_val\n",
    "                index += 1\n",
    "            new_x = x_func(x)\n",
    "            if new_x in self.values: new_psi_val, new_nn_val = self.values[new_x], self.nn_output[new_x]\n",
    "            else: new_psi_val, new_nn_val = psi(new_x)\n",
    "            ratio = abs(new_psi_val) ** 2 / abs(psi_val) ** 2\n",
    "            if ratio > 1 or ratio > rand_uniform[index]:\n",
    "                self.distribution[new_x] = self.distribution.get(new_x, 0) + 1\n",
    "                self.list.append(new_x)\n",
    "                x = new_x \n",
    "                psi_val = new_psi_val \n",
    "            else: \n",
    "                self.distribution[x] = self.distribution.get(x, 0) + 1\n",
    "                self.list.append(x)\n",
    "            self.values[new_x] = new_psi_val\n",
    "            self.nn_output[new_x] = new_nn_val\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_amp_phase(nn_output):\n",
    "    return torch.exp(nn_output[:, 0] + 1.j * nn_output[:, 1])\n",
    "def bitflip_x(x, N, flips):\n",
    "    new_x = x\n",
    "    for _ in range(flips):\n",
    "        new_x = x ^ (1 << npr.randint(0, N))\n",
    "    return new_x\n",
    "# only for nn_output = (log(amp), phase)\n",
    "def generate_eloc_list(sampled_vector, N, J, Gamma, model):\n",
    "    nn_output_calcs = {}\n",
    "    def model_to_output(x):\n",
    "        if x in sampled_vector.nn_output:\n",
    "            return sampled_vector.nn_output[x]\n",
    "        if x in nn_output_calcs:\n",
    "            return nn_output_calcs[x]\n",
    "        tens = torch.tensor([lib.generate_state_array(x, N)], dtype = torch.float32)\n",
    "        output = model(tens)[0]\n",
    "        nn_output_calcs[x] = output\n",
    "        return output\n",
    "\n",
    "    eloc_values = []\n",
    "    for basis_state in sampled_vector.list:\n",
    "        eloc = 0\n",
    "        output = model_to_output(basis_state)\n",
    "        for adjacency in lib.generate_adjacencies(basis_state, N):\n",
    "            output_prime = model_to_output(adjacency)\n",
    "            eloc += lib.calc_H_elem(N, J, Gamma, basis_state, adjacency) * torch.exp(output_prime[0] - output[0] + 1.j * 2 * np.pi * (output_prime[1] - output[1]))\n",
    "        eloc += lib.calc_H_elem(N, J, Gamma, basis_state, basis_state)\n",
    "        eloc_values.append(eloc)\n",
    "    return eloc_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_gradients(sampled_vector, N, J, Gamma, model): # also only for log(amp), phase\n",
    "    nn_output_calcs = {}\n",
    "    def model_to_output(x):\n",
    "        if x in sampled_vector.nn_output:\n",
    "            return sampled_vector.nn_output[x]\n",
    "        if x in nn_output_calcs:\n",
    "            return nn_output_calcs[x]\n",
    "        tens = torch.tensor([lib.generate_state_array(x, N)], dtype = torch.float32)\n",
    "        output = model(tens)[0]\n",
    "        nn_output_calcs[x] = output\n",
    "        return output\n",
    "    def output_to_log(x):\n",
    "        return x[0] + 1.j * x[1]\n",
    "\n",
    "    params = [n for n in model.parameters()]\n",
    "    energy = lib.TFIM_expectation_using_locals(sampled_vector, N, J, Gamma, model, log_amp_phase)\n",
    "    for i in range(len(params)):\n",
    "        p = params[i]\n",
    "        grad = torch.zeros(p.shape)\n",
    "        tot = 0\n",
    "        for basis_state in sampled_vector.list:\n",
    "            for adjacency in lib.generate_adjacencies(basis_state, N):\n",
    "                log_psi = output_to_log(model_to_output(basis_state))\n",
    "                log_psi_p = output_to_log(model_to_output(adjacency))\n",
    "                tot += lib.calc_H_elem(N, J, Gamma, basis_state, adjacency) * torch.exp(log_psi_p - log_psi).detach()\n",
    "        avg = tot / len(sampled_vector.list)\n",
    "\n",
    "        for basis_state in sampled_vector.distribution:\n",
    "            for adjacency in lib.generate_adjacencies(basis_state, N):\n",
    "                log_psi = output_to_log(model_to_output(basis_state))\n",
    "                log_psi_p = output_to_log(model_to_output(adjacency))\n",
    "                \n",
    "                log_psi.conj().real.backward(retain_graph=True)\n",
    "                grad_re_log = p.grad.clone()\n",
    "                log_psi.conj().imag.backward(retain_graph=True)\n",
    "                grad_im_log = p.grad.clone()\n",
    "\n",
    "                mag_psi = abs(torch.exp(log_psi)).detach()\n",
    "                H_psi_over_psi = lib.calc_H_elem(N, J, Gamma, basis_state, adjacency) * torch.exp(log_psi_p - log_psi).detach() - avg\n",
    "                grad += mag_psi ** 2 * (grad_re_log * H_psi_over_psi.real - grad_im_log * H_psi_over_psi.imag)\n",
    "\n",
    "                # print(log_psi, log_psi_p, grad_re_log, grad_im_log, mag_psi, psi_over_psi)\n",
    "        p.grad = grad\n",
    "        # psi_times_psi = SparseStateVector.inner_product(sampled_vector, sampled_vector).real\n",
    "        #sum(abs(torch.exp(output_to_log(model_to_output(basis_state)))) ** 2 for basis_state in sampled_vector.distribution)\n",
    "        # torch.log(psi_times_psi).backward(retain_graph=True)\n",
    "        # grad_log_psi_psi = p.grad.clone()\n",
    "\n",
    "        # p.grad = grad / psi_times_psi.detach() - grad_log_psi_psi * energy.detach()\n",
    "    return energy\n",
    "\n",
    "def update_gradients(model, lr):\n",
    "    with torch.no_grad():\n",
    "        for p in model.parameters():\n",
    "            p -= lr * p.grad \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 6; J = 1; Gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "layers.append(nn.Linear(N, 32))\n",
    "for _ in range(2):\n",
    "    layers.append(nn.Linear(32, 32))\n",
    "    layers.append(nn.SELU())\n",
    "layers.append(nn.Linear(32, 2))\n",
    "model = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.2399e-01, -6.9577e-02,  2.0703e-01,  2.7970e-01,  1.7864e-01,\n",
      "         -2.8881e-01],\n",
      "        [ 2.4756e-01,  2.9709e-01, -2.8225e-01,  8.7880e-02, -1.7080e-01,\n",
      "         -3.0567e-02],\n",
      "        [ 2.0476e-01, -2.4860e-01, -3.1950e-02,  2.6819e-02, -1.0525e-01,\n",
      "         -3.7605e-01],\n",
      "        [ 2.9361e-01, -2.0021e-04,  6.7889e-02, -3.1584e-01, -3.4393e-02,\n",
      "          2.3144e-01],\n",
      "        [-2.7328e-01,  2.4530e-01, -3.9614e-01, -1.2676e-01, -1.1906e-01,\n",
      "          2.6199e-02],\n",
      "        [-3.4742e-01,  2.0432e-01, -2.5909e-01,  3.3132e-01, -3.7207e-01,\n",
      "          3.4773e-01],\n",
      "        [-4.0441e-01, -2.6788e-01,  3.3489e-02, -3.3940e-01, -2.5297e-01,\n",
      "         -3.8853e-01],\n",
      "        [ 1.2889e-01,  1.3381e-01, -1.7449e-01,  3.8351e-02,  3.6061e-01,\n",
      "          6.2137e-03],\n",
      "        [-2.1327e-01, -3.8807e-01,  3.4640e-01,  3.2096e-01,  1.3811e-01,\n",
      "          3.0136e-01],\n",
      "        [-1.4434e-01, -5.5235e-02,  5.5037e-02, -2.3440e-01,  1.3363e-01,\n",
      "          1.4014e-01],\n",
      "        [ 5.1055e-02, -3.7771e-01,  4.8450e-02, -3.4991e-01, -1.7260e-02,\n",
      "          3.5835e-01],\n",
      "        [ 3.1219e-01, -3.8108e-01, -2.2094e-01,  6.9888e-02,  1.8297e-01,\n",
      "          2.6717e-01],\n",
      "        [ 2.0841e-01,  3.6709e-01,  1.7182e-03, -2.5320e-01, -3.8324e-01,\n",
      "          6.3503e-02],\n",
      "        [ 1.8833e-01,  1.7136e-01,  2.1422e-01, -2.4325e-01, -3.4536e-01,\n",
      "          1.8272e-02],\n",
      "        [ 1.6397e-01,  1.1789e-01,  3.0810e-01, -3.0724e-03, -3.4886e-01,\n",
      "         -7.2342e-02],\n",
      "        [ 5.3221e-04,  3.1015e-02,  3.0561e-02,  2.1340e-01, -2.7550e-01,\n",
      "          2.0649e-01],\n",
      "        [-2.7007e-02, -2.5944e-01, -5.0552e-02, -3.7452e-01, -1.6088e-01,\n",
      "         -1.3465e-02],\n",
      "        [-4.3639e-02,  2.8811e-01,  3.4841e-01, -2.2366e-01, -5.6817e-02,\n",
      "         -3.5311e-01],\n",
      "        [ 3.5412e-01, -3.9562e-01,  1.3909e-01,  2.2586e-01, -9.5950e-02,\n",
      "          3.5377e-02],\n",
      "        [-3.9045e-01, -6.0391e-02,  3.7813e-01,  3.7035e-01,  9.2867e-02,\n",
      "          9.8350e-02],\n",
      "        [-3.8072e-01,  3.3632e-01,  3.4299e-01,  1.1635e-01, -3.7352e-01,\n",
      "         -3.5525e-01],\n",
      "        [ 1.6000e-01, -3.4309e-01,  3.9557e-01, -2.1697e-01, -7.2004e-02,\n",
      "          1.4883e-01],\n",
      "        [ 2.0606e-01, -1.8478e-01,  1.7816e-01, -1.1415e-02,  3.1625e-01,\n",
      "         -2.4135e-01],\n",
      "        [ 1.6071e-01, -2.7778e-02,  2.3863e-01,  1.2329e-01,  2.5248e-01,\n",
      "         -3.3301e-01],\n",
      "        [ 2.5081e-01, -3.2684e-01,  4.4391e-02,  9.3282e-02,  2.5160e-01,\n",
      "          4.0627e-01],\n",
      "        [-4.4749e-02,  2.8710e-01, -1.0834e-01,  1.0522e-01,  2.6845e-01,\n",
      "          6.3554e-02],\n",
      "        [-2.2870e-02, -1.9226e-01, -1.3989e-01, -5.4323e-02,  1.3106e-01,\n",
      "          2.9577e-01],\n",
      "        [ 3.3116e-01, -5.7352e-02,  2.3673e-03,  3.3179e-01,  2.7305e-01,\n",
      "         -1.0234e-01],\n",
      "        [ 1.4155e-01, -2.2871e-01,  4.6575e-02, -1.6960e-01,  4.4683e-02,\n",
      "          1.5774e-01],\n",
      "        [-9.0161e-02, -3.0682e-01,  3.4209e-02, -3.1155e-01,  1.9863e-01,\n",
      "          2.6191e-01],\n",
      "        [-2.4785e-01,  2.3627e-01, -1.6472e-01,  4.2836e-02,  1.9744e-01,\n",
      "         -1.3945e-01],\n",
      "        [ 3.1563e-01,  3.9549e-01,  3.5780e-01, -2.4364e-01, -2.3213e-01,\n",
      "          4.0469e-01]], requires_grad=True)\n",
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "params = [n for n in model.parameters()]\n",
    "print(params[0])\n",
    "params[0] = torch.zeros(params[0].shape)\n",
    "print(params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "data_rate = 1\n",
    "num_samples = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(-0.6855, grad_fn=<SelectBackward0>)\n",
      "1 tensor(-0.8520, grad_fn=<SelectBackward0>)\n",
      "2 tensor(-0.9844, grad_fn=<SelectBackward0>)\n",
      "3 tensor(-1.1351, grad_fn=<SelectBackward0>)\n",
      "4 tensor(-1.3058, grad_fn=<SelectBackward0>)\n",
      "5 tensor(-1.5043, grad_fn=<SelectBackward0>)\n",
      "6 tensor(-1.7415, grad_fn=<SelectBackward0>)\n",
      "7 tensor(-2.0257, grad_fn=<SelectBackward0>)\n",
      "8 tensor(-2.3663, grad_fn=<SelectBackward0>)\n",
      "9 tensor(-2.7730, grad_fn=<SelectBackward0>)\n",
      "10 tensor(-3.2517, grad_fn=<SelectBackward0>)\n",
      "11 tensor(-3.7958, grad_fn=<SelectBackward0>)\n",
      "12 tensor(-4.3776, grad_fn=<SelectBackward0>)\n",
      "13 tensor(-4.9396, grad_fn=<SelectBackward0>)\n",
      "14 tensor(-5.4076, grad_fn=<SelectBackward0>)\n",
      "15 tensor(-5.7279, grad_fn=<SelectBackward0>)\n",
      "16 tensor(-5.9100, grad_fn=<SelectBackward0>)\n",
      "17 tensor(-5.9898, grad_fn=<SelectBackward0>)\n",
      "18 tensor(-6.0010, grad_fn=<SelectBackward0>)\n",
      "19 tensor(nan, grad_fn=<SelectBackward0>)\n",
      "20 tensor(nan, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m mh_state \u001b[38;5;241m=\u001b[39m UniformNeuralState(N, model, log_amp_phase, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m N)\n\u001b[0;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 8\u001b[0m energy \u001b[38;5;241m=\u001b[39m \u001b[43mset_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmh_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# energy = lib.TFIM_expectation_using_locals(mh_state, N, J, Gamma, model, log_amp_phase)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[4], line 38\u001b[0m, in \u001b[0;36mset_gradients\u001b[1;34m(sampled_vector, N, J, Gamma, model)\u001b[0m\n\u001b[0;32m     35\u001b[0m log_psi\u001b[38;5;241m.\u001b[39mconj()\u001b[38;5;241m.\u001b[39mimag\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     36\u001b[0m grad_im_log \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m---> 38\u001b[0m mag_psi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_psi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m H_psi_over_psi \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mcalc_H_elem(N, J, Gamma, basis_state, adjacency) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(log_psi_p \u001b[38;5;241m-\u001b[39m log_psi)\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m-\u001b[39m avg\n\u001b[0;32m     40\u001b[0m grad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mag_psi \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (grad_re_log \u001b[38;5;241m*\u001b[39m H_psi_over_psi\u001b[38;5;241m.\u001b[39mreal \u001b[38;5;241m-\u001b[39m grad_im_log \u001b[38;5;241m*\u001b[39m H_psi_over_psi\u001b[38;5;241m.\u001b[39mimag)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = []\n",
    "energy_data = []\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-5)\n",
    "for epoch in range(num_epochs):\n",
    "    # mh_state = MHNeuralState(N, model, log_amp_phase, lambda x: bitflip_x(x, N, 1), 2 ** (N - 1), num_samples)\n",
    "    mh_state = UniformNeuralState(N, model, log_amp_phase, 2 ** N)\n",
    "    optimizer.zero_grad()\n",
    "    energy = set_gradients(mh_state, N, J, Gamma, model)\n",
    "    # energy = lib.TFIM_expectation_using_locals(mh_state, N, J, Gamma, model, log_amp_phase)\n",
    "    optimizer.step()\n",
    "    # update_gradients(model, 1e-5)\n",
    "    if epoch % data_rate == 0:\n",
    "        energy_data.append(energy.item().real)\n",
    "        epochs.append(epoch)\n",
    "    if epoch % 1 == 0:\n",
    "        print(epoch, energy)\n",
    "print(energy_data[-1])\n",
    "print(min(energy_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
