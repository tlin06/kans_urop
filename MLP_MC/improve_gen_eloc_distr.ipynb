{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b67fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import libraries.tfim_functions as tfim_functions\n",
    "import libraries.utils as utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from libraries.NeuralStates import *\n",
    "from kan import MultKAN\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "356a1fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_eloc_distr(sampled_vector, N, J, Gamma, model):\n",
    "    nn_output_calcs = {}\n",
    "    def model_to_output(x):\n",
    "        if x in sampled_vector.nn_output:\n",
    "            return sampled_vector.nn_output[x]\n",
    "        if x in nn_output_calcs:\n",
    "            return nn_output_calcs[x]\n",
    "        tens = torch.tensor([utils.generate_state_array(x, N)], dtype = torch.float32)\n",
    "        output = model(tens)[0]\n",
    "        nn_output_calcs[x] = output\n",
    "        return output\n",
    "    \n",
    "    eloc_values = {}\n",
    "    for basis_state in sampled_vector.distribution:\n",
    "        eloc = 0\n",
    "        output = model_to_output(basis_state)\n",
    "        for adjacency in tfim_functions.generate_adjacencies(basis_state, N):\n",
    "            output_prime = model_to_output(adjacency)\n",
    "            eloc += tfim_functions.calc_H_elem(N, J, Gamma, basis_state, adjacency) * torch.exp(output_prime[0] - output[0] + 1.j * (output_prime[1] - output[1]))\n",
    "        eloc_values[basis_state] = eloc\n",
    "    return eloc_values\n",
    "\n",
    "def generate_eloc_distr_efficient(sampled_vector, N, J, Gamma, model):\n",
    "    to_calculate = []\n",
    "    visited = {}\n",
    "    for basis_state in sampled_vector.distribution:\n",
    "        for adj in tfim_functions.generate_adjacencies(basis_state, N):\n",
    "            if adj not in sampled_vector.nn_output and adj not in visited:\n",
    "                to_calculate.append(adj)\n",
    "                visited[adj] = len(to_calculate) - 1\n",
    "    nn_output_calcs = model(utils.generate_input_samples(N, to_calculate)) if to_calculate else None\n",
    "\n",
    "    def model_to_output(x):\n",
    "        if x in sampled_vector.nn_output:\n",
    "            return sampled_vector.nn_output[x]\n",
    "        if x in visited:\n",
    "            return nn_output_calcs[visited[x]]\n",
    "        raise Exception('should not reach')\n",
    "    \n",
    "    eloc_values = {}\n",
    "    for basis_state in sampled_vector.distribution:\n",
    "        eloc = 0\n",
    "        output = model_to_output(basis_state)\n",
    "        for adjacency in tfim_functions.generate_adjacencies(basis_state, N):\n",
    "            output_prime = model_to_output(adjacency)\n",
    "            eloc += tfim_functions.calc_H_elem(N, J, Gamma, basis_state, adjacency) * torch.exp(output_prime[0] - output[0] + 1.j * (output_prime[1] - output[1]))\n",
    "        eloc_values[basis_state] = eloc\n",
    "    return eloc_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52bfde43",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2\n",
    "layers = []\n",
    "layers.append(nn.Linear(N, 32))\n",
    "for _ in range(2):\n",
    "    layers.append(nn.Linear(32, 32))\n",
    "    layers.append(nn.SELU())\n",
    "layers.append(nn.Linear(32, 2))\n",
    "mlp_model = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c5a7ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mh_state = MHNeuralState(N, mlp_model, utils.log_amp_phase, lambda x: utils.bitflip_x(x, N, 1), 0, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24328f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: tensor(-0.0354-0.1061j, grad_fn=<AddBackward0>),\n",
       " 0: tensor(-4.2279+0.3627j, grad_fn=<AddBackward0>),\n",
       " 1: tensor(0.0606+0.1998j, grad_fn=<AddBackward0>),\n",
       " 3: tensor(-3.7272-0.3018j, grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_eloc_distr(mlp_mh_state, N, 1, 1, mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ae70c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: tensor(-0.0354-0.1061j, grad_fn=<AddBackward0>),\n",
       " 0: tensor(-4.2279+0.3627j, grad_fn=<AddBackward0>),\n",
       " 1: tensor(0.0606+0.1998j, grad_fn=<AddBackward0>),\n",
       " 3: tensor(-3.7272-0.3018j, grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_eloc_distr_efficient(mlp_mh_state, N, 1, 1, mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "430ab94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "layers = []\n",
    "layers.append(nn.Linear(N, 32))\n",
    "for _ in range(2):\n",
    "    layers.append(nn.Linear(32, 32))\n",
    "    layers.append(nn.SELU())\n",
    "layers.append(nn.Linear(32, 2))\n",
    "mlp_model = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d929522",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mh_state = MHNeuralState(N, mlp_model, utils.log_amp_phase, lambda x: utils.bitflip_x(x, N, 1), 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52180026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: tensor(-15.6724+0.1789j, grad_fn=<AddBackward0>),\n",
       " 36: tensor(-12.0176+0.0248j, grad_fn=<AddBackward0>),\n",
       " 548: tensor(-8.0692+0.0849j, grad_fn=<AddBackward0>),\n",
       " 32: tensor(-16.0977-0.0167j, grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_eloc_distr(mlp_mh_state, N, 1, 1, mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cae19f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: tensor(-15.6724+0.1789j, grad_fn=<AddBackward0>),\n",
       " 36: tensor(-12.0176+0.0248j, grad_fn=<AddBackward0>),\n",
       " 548: tensor(-8.0692+0.0849j, grad_fn=<AddBackward0>),\n",
       " 32: tensor(-16.0977-0.0167j, grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_eloc_distr_efficient(mlp_mh_state, N, 1, 1, mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4557548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mh_state_256 = MHNeuralState(N, mlp_model, utils.log_amp_phase, lambda x: utils.bitflip_x(x, N, 1), 0, 256)\n",
    "# as num_samples goes up, the batched/unbatched times approach each other as the number of additional calculations goes to 0\n",
    "# as num_samples gets smaller, we get more improvement in batching since more of the adjacent states haven't already been calculated\n",
    "# ~ 3x improvement for num_samples=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c87fe44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP unbatched time: 0.1987898349761963\n",
      "MLP batched time: 0.09864926338195801\n"
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "generate_eloc_distr(mlp_mh_state_256, N, 1, 1, mlp_model)\n",
    "print(f'MLP unbatched time: {time.time() - start}')\n",
    "start = time.time() \n",
    "generate_eloc_distr_efficient(mlp_mh_state_256, N, 1, 1, mlp_model)\n",
    "print(f'MLP batched time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dafca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:813: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:823: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:824: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "c:\\Users\\taoha\\anaconda3\\envs\\kans\\Lib\\site-packages\\kan\\MultKAN.py:825: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    }
   ],
   "source": [
    "kan_model = MultKAN(width=[N, N, 2], device='cpu')\n",
    "kan_mh_state = MHNeuralState(N, kan_model, utils.log_amp_phase, lambda x: utils.bitflip_x(x, N, 1), 0, 256)\n",
    "# batching seems to provide massive improvement regardless of num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b502954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAN unbatched time: 10.611034393310547\n",
      "KAN batched time: 0.17409944534301758\n"
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "generate_eloc_distr(kan_mh_state, N, 1, 1, kan_model)\n",
    "print(f'KAN unbatched time: {time.time() - start}')\n",
    "start = time.time() \n",
    "generate_eloc_distr_efficient(kan_mh_state, N, 1, 1, kan_model)\n",
    "print(f'KAN batched time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a71a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
